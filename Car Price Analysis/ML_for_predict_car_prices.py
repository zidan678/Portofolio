# -*- coding: utf-8 -*-
"""ML_for_predict_car_prices.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CQcUGEf4THtojxf_ZmbxR3lgB3u1Kr7B
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression

#Model ML
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor
import xgboost as xgb

from google.colab import files
uploaded =files.upload()

df=pd.read_csv('car_sales_data.csv')
df.head()

df['Manufacturer'].value_counts()

df_encoded = pd.get_dummies(df, columns=['Fuel type', 'Model', 'Manufacturer'])
df_encoded

print(df_encoded.dtypes)

x = df_encoded.drop('Price', axis =1)
y = df_encoded['Price']

df_encoded.info()

X_train, X_test, y_train, y_test= train_test_split(x, y, test_size=0.2, random_state=42)

print(X_train.dtypes)
print(y_train.dtypes)

dt= DecisionTreeRegressor(random_state=42)
dt.fit(X_train, y_train)

y_pred_dt=dt.predict(X_test)

print(X_test.shape)
print(y_test.shape)

# === Linear Regression ===
lr=LinearRegression()
lr.fit(X_train, y_train)
y_pred_lr=lr.predict(X_test)
print("Decision Tree  R² : ", r2_score(y_test, y_pred_lr))
print("Decision Tree RMSE : ", np.sqrt(mean_squared_error(y_test, y_pred_lr)))

# === Decision Tree ===
dt= DecisionTreeRegressor(random_state=42)
dt.fit(X_train, y_train)

dt.predict(X_test)
print("Decision Tree  R² : ", r2_score(y_test, y_pred_dt))
print("Decision Tree RMSE : ", np.sqrt(mean_squared_error(y_test, y_pred_dt)))

# === Random Forest ===
rf=RandomForestRegressor( n_estimators= 100, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf=rf.predict(X_test)
print("Decision Tree  R² : ", r2_score(y_test, y_pred_rf))
print("Decision Tree RMSE : ", np.sqrt(mean_squared_error(y_test, y_pred_rf)))

# === Gradient Boosting ===
gb= GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
gb.fit(X_train, y_train)
y_pred_gb=gb.predict(X_test)
print("Decision Tree  R² : ", r2_score(y_test, y_pred_gb))
print("Decision Tree RMSE : ", np.sqrt(mean_squared_error(y_test, y_pred_gb)))

results=({"Model" : ["Linear Regresion",
                     "Decision Tree",
                     "Random Forest ",
                     "Gradient Boosting"],
                "R²" : [r2_score(y_test, y_pred_lr),
                        r2_score(y_test, y_pred_dt),
                        r2_score(y_test, y_pred_rf),
                        r2_score(y_test, y_pred_gb)],
                "RMSE" : [np.sqrt(mean_squared_error(y_test, y_pred_dt)),
                          np.sqrt(mean_squared_error(y_test, y_pred_dt)),
                          np.sqrt(mean_squared_error(y_test, y_pred_rf)),
                          np.sqrt(mean_squared_error(y_test, y_pred_gb))]})

pd.DataFrame(results)

X_train, X_test, y_train, y_test= train_test_split(x, y, test_size=0.2, random_state=42)

#Most Important Values
importances = pd.Series(dt.feature_importances_, index=x.columns)
importances.sort_values(ascending=False)

"""##Importances values Chart"""

k=importances.sort_values(ascending=False)

# Assuming 'k' is a Series containing feature importance values
# Filtering values greater than 0.01
filtered_k = k[k > 0.01]

plt.figure(figsize=(12, 8))
plt.pie(filtered_k, startangle=240, colors=plt.cm.tab20.colors)
plt.legend(labels=[f"{label}: {value:.1f}%" for label, value in zip(filtered_k.index, filtered_k/filtered_k.sum()*100)], loc="best")
plt.title("Importances values greater than 0.01")

plt.axis('equal')
plt.show()

# Displaying the summary table
print(filtered_k)

"""#Step by step guide

### Prepare the Input Data:

1. **Create a Dictionary**:
   Create a dictionary that contains all the necessary attributes of the car you want to predict the price for. In the example, the dictionary `sample` includes:
   - **Model**: The model name of the car.
   - **Engine size**: The size of the engine in liters.
   - **Fuel type**: The type of fuel the car uses (e.g., Petrol).
   - **Year of manufacture**: The year the car was manufactured.
   - **Mileage**: The total distance the car has traveled (in kilometers).
   - **Manufacturer attributes** (e.g., `Manufacturer_BMW`): These are binary indicators (0 or 1) that specify the car's manufacturer.

### Convert to DataFrame:

2. **Use Pandas**:
   Use pandas to convert the dictionary into a DataFrame. This is done using `pd.DataFrame([sample])`, which creates a DataFrame from the list containing the dictionary.

### One-Hot Encoding:

3. **Encoding Categorical Variables**:
   If your training data used one-hot encoding for categorical variables, you should do the same for the new input data. The `pd.get_dummies(sample_df)` function converts categorical variables in `sample_df` into a format that can be used in machine learning models (i.e., it creates binary columns for each category).

### Reindexing:

4. **Reorder Columns**:
   After encoding, the columns of the new DataFrame may not match the columns of the training data (`X_train`). Use `reindex` to reorder the columns of `sample_df_encoded` to match `X_train`, filling any missing columns with 0. This ensures that the input to the model has the same structure as the training data.
### Choose a Model:

5. **Select a Model**:
   You can choose between different models for prediction, such as:
   - **Linear Regression (lr)**
   - **Decision Tree (dt)**
   - **Random Forest (rf)**
   - **Gradient Boosting (gb)**
   Ensure that the chosen model is already trained.
### Make a Prediction:

6. **Predict the Price**:
   Use your trained model (in this case, `dt`, which could be a Decision Tree model) to predict the price of the car. The `predict` method takes the encoded DataFrame as input and returns the predicted price.

### Display the Result:

7. **Format and Print**:
   Finally, format and print the predicted price using Python's formatted string capabilities. The `:,.0f` format specifier is used to display the price with commas as thousands separators and no decimal places.
"""

# Function to get valid input
def get_valid_input(prompt, type_func, condition=None):
    while True:
        try:
            value = type_func(input(prompt))
            if condition and not condition(value):
                print("Input does not meet the required condition. Please try again.")
                continue
            return value
        except ValueError:
            print("Invalid input. Please enter an appropriate value.")

# Get user input
Model = input("Enter car model (e.g., M5, 911): ")

Engine_size = get_valid_input(
    "Enter engine size (e.g., 2.0): ",
    float,
    condition=lambda x: x > 0  # Ensure engine size is positive
)

Year_of_manufacture = get_valid_input(
    "Enter car manufacturing year (e.g., 2020): ",
    int,
    condition=lambda x: x >= 1886  # Only lower bound, no upper bound
)

Mileage = get_valid_input(
    "Enter car mileage (e.g., 100000): ",
    float,
    condition=lambda x: x >= 0  # Ensure mileage is not negative
)

Manufacturer = input("Enter car manufacturer (e.g., BMW, Ford, Porsche, Toyota, VW): ")

# Determine manufacturer based on user input
Manufacturer_BMW = 1 if Manufacturer.lower() == "bmw" else 0
Manufacturer_Ford = 1 if Manufacturer.lower() == "ford" else 0
Manufacturer_Porsche = 1 if Manufacturer.lower() == "porsche" else 0
Manufacturer_Toyota = 1 if Manufacturer.lower() == "toyota" else 0
Manufacturer_VW = 1 if Manufacturer.lower() == "vw" else 0

# Create sample dictionary
sample = {
    "Model": Model,
    "Engine size": Engine_size,
    "Fuel type": "",
    "Year of manufacture": Year_of_manufacture,
    "Mileage": Mileage,
    "Manufacturer_BMW": Manufacturer_BMW,
    "Manufacturer_Ford": Manufacturer_Ford,
    "Manufacturer_Porsche": Manufacturer_Porsche,
    "Manufacturer_Toyota": Manufacturer_Toyota,
    "Manufacturer_VW": Manufacturer_VW
}

print("----------------------------------------------------")
# Display sample
print(pd.Series(sample))

#Example
sample = {
    "Model": Model,
    "Engine size": Engine_size,
    "Fuel type": "",
    "Year of manufacture": Year_of_manufacture,
    "Mileage": Mileage,
    "Manufacturer_BMW": Manufacturer_BMW,
    "Manufacturer_Ford": Manufacturer_Ford,
    "Manufacturer_Porsche": Manufacturer_Porsche,
    "Manufacturer_Toyota": Manufacturer_Toyota,
    "Manufacturer_VW": Manufacturer_VW
}

# Convert to DataFrame
import pandas as pd
sample_df = pd.DataFrame([sample])

# Ensure using all columns that match the training data

sample_df_encoded = pd.get_dummies(sample_df)

# Reindex to match the order of columns in X_train
sample_df_encoded = sample_df_encoded.reindex(columns=X_train.columns, fill_value=0)

# Prediction
#you can use lr, dt, rf, gb
#in this case we using dt
pred_price = dt.predict(sample_df_encoded)
print(f"Predicted car price: USD: {pred_price[0]:,.0f}")















